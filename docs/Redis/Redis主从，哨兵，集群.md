# 增量复制

### 🔸 场景：主节点执行一条写命令，如 `SET key 123`

#### 主节点会做 3 件事：

1. **执行命令 → 更新主节点内存**
2. **（如果开启 AOF）写入 AOF buffer（稍后刷盘）**
3. **广播该命令给所有从节点，并写入 `backlog buffer`**

------

### ✅ 重点来了：

> **这一步是**：“只要主节点执行了命令，就立即把这条命令内容写入 `replication backlog buffer`” —— ✅ **和从节点是否在线、是否收到了**，**没有任何关系**。



# 总结

## 🧩 二、复制的三种状态阶段

我们从 Redis 的**复制生命周期**来看，可以分为以下阶段：

### 1️⃣ 主从连接建立

从节点通过以下命令发起复制请求：

```
SLAVEOF <master-ip> <master-port>
```

→ 主节点注册这个从节点 → 两者之间建立 **TCP socket 连接**

------

### 2️⃣ 同步过程（两种情况）

同步有两种模式：

#### ✅ 全量同步（Full Resync）

触发条件：

- 从节点第一次连接
- 主从 offset 不一致（offset 丢失）

执行流程：

```java
1. 从节点发送 PSYNC ? -1
2. 主节点 fork 子进程生成 RDB 快照（snapshot）
3. 主节点将 RDB 文件通过 socket 传给从节点
4. 期间主节点还在接收写命令 → 这些命令写入 backlog buffer
5. RDB 发送完成后 → backlog buffer 中的命令也一并发送
6. 从节点完成数据加载 → 与主节点同步一致
```

> ✅ Redis 不支持只增量发内存数据，所以必须用 RDB 全量替换。

------

#### ✅ 增量同步（Partial Resync）

触发条件：

- 从节点断线重连
- 提供了上一次主节点的 runId 和 offset
- 主节点的 backlog buffer 中 **仍然保留着 offset 之后的命令**

执行流程：

```
1. 从节点发送 PSYNC <runId> <offset>
2. 主节点检查 offset 是否命中 backlog buffer
3. 如果命中 → 直接从该位置开始发送命令（无需发 RDB）
4. 否则回退到全量同步
```

------

### 3️⃣ 运行时命令复制（实时同步）

复制建立后，进入持续同步状态：

```
每当主节点执行写命令：
→ 写入主节点内存
→ 写入 replication backlog buffer
→ 通过 socket 推送命令到所有从节点
→ 从节点收到后立即执行
```

> ✅ 这是 Redis 主从复制的核心运行机制 —— 实时推送命令。

------

## 🧩 三、重点概念：replication backlog buffer

| 属性           | 说明                                                 |
| -------------- | ---------------------------------------------------- |
| 类型           | 主节点的一个环形缓冲区                               |
| 用途           | 存放最近发送给从节点的“命令内容”                     |
| 大小（默认）   | 1MB，可通过 `repl-backlog-size` 配置                 |
| 会不会被覆盖？ | 会！写满后从头覆盖                                   |
| 是否写入磁盘？ | ❌ 绝不会，它只在内存中                               |
| 作用           | 为增量复制提供命令数据                               |
| 和 AOF 的区别  | AOF 是为持久化，写入磁盘；backlog 是为复制，驻留内存 |

> ✅ 主节点写命令时**不管从节点是否在线**，也会把命令写入 backlog，确保断线后能补发。

## 🧩 四、复制是异步的，但支持“可选同步”

### Redis 默认是**异步复制**：

> 主节点写命令后 **立即响应客户端**，不会等待从节点确认，哪怕从节点宕机、断网、延迟。

### 可选使用 `WAIT` 命令实现“半同步”：

```
WAIT 2 1000  # 等待 2 个副本在 1 秒内确认接收到写命令
```

这用于对强一致有要求的场景，但会影响性能。





# 在哨兵转化的时候

------

## 📌 场景设定：

你是字节跳动电商部的后端，负责一个秒杀下单系统。

- 用户点了「立即购买」，前端请求发来。
- 后端系统做了库存校验，构建订单对象。
- 你现在要把这个订单记录下来。

------

## ✅ 为什么不能直接写数据库？

- 数据库写入太慢，容易成为瓶颈（高并发死锁）
- Redis 更快，适合做缓存或中转

------

## ✅你的做法：写两份

```java
// 1. 把订单写入 Redis（快速响应客户端）
redis.set("order:123456", order);

// 2. 同时写入 Kafka（异步消费入库）
kafka.send("order-topic", order);
```

### 🎯 Redis 的作用：

- 快速响应
- 支持幂等判断（是否重复下单）

### 🎯 Kafka 的作用：

- 异步消息投递 → 下游消费者（写入 MySQL + 发送短信 + 打印小票）

------

## 😵 Redis 崩了怎么办？

- 客户端确实得到了订单成功的响应（因为 Redis 写成功）
- 但 Redis 宕机后重启，数据丢了
- **还好你写了 Kafka**，消费者会从 Kafka 中**重新补回**数据库的订单

✅ 所以这类场景叫**最终一致性可接受**：
**数据可以晚一点写入，但不能完全没了；**写 Kafka 就是为了兜底。



## 第二个方案——poxy 代理

# ✅ 问题核心

> Redis 主从切换的几秒钟内，客户端仍可能不断发指令。这些指令如果直接发给 Redis，会因为连接断了、主节点没选出来、或者打偏方向，造成 **指令丢失、报错、甚至打到旧主写错数据**。

而**Redis Proxy 的核心职责**，就是：
 ✅ 接管客户端请求 +
 ✅ 屏蔽主从切换细节 +
 ✅ 保证请求不会丢、不会错、不会打偏

------

## 🎯 Redis Proxy 的三层处理逻辑（重点在这里）

我们以阿里 TairProxy / Codis / 字节 KvProxy 的通用逻辑为基础：

------

### ① 路由层：实时感知主从角色变化

- Proxy 会**定期或通过订阅方式监听 Redis 主从信息**（如来自 Sentinel）

- 它维护一个**本地路由表**：

  ```
  {
    "order:123" → 10.0.0.1:6379 (当前主)
  }
  ```

- 一旦哨兵切换完成或探测到主节点挂了：
   ✅ Proxy 会**将主节点 IP 替换为新主 IP**

------

### ② 写请求拦截层：判断当前主是否“健康可写”

- 如果客户端发来了 `SET` 等写请求
- Proxy 会判断：

```
if (当前主节点状态 == "在线" && isWritable) {
    转发请求
} else {
    暂停 + 重试队列 + 降级
}
```

🔁 **在主节点正在切换、尚未就绪期间**：

- Proxy **不会立刻把写请求打出去**
- 而是：
  - 将请求缓存在内存队列中（小窗口缓存）
  - 或者直接返回“Redis 当前不可用，请稍后重试”
  - 或者降级走 DB/MQ 等兜底逻辑（在企业内部可配置）

------

### ③ 指令重试 + 最终一致兜底

- 当新主节点选定 + 连接建立 + 探测健康 ✅
- Proxy 会重新尝试发送刚才缓存的请求
- 或通过 MQ 重放机制补偿（可选）

------

## 💡 举个真实流程图例子

```
【你提交了一个订单 SET 指令】
↓
Client → RedisProxy（你只连 Proxy）

Redis 主节点宕机
↓
Proxy 探测主节点连接失败
↓
1. 暂停路由更新
2. 队列缓存该 SET 请求
3. 查询哨兵 / Meta Server 得知新主为 10.0.0.2
4. 等待新主就绪（ping 成功）

↓
连接新主成功
↓
将该 SET 指令重新发给新主
↓
客户端毫无感知：业务请求成功
```

------

## 🧠 面试时你可以这么回答：

> Redis Proxy 在故障切主期间的关键作用，是拦截客户端指令、判断主节点可写性，并通过本地路由动态更新 + 内存缓冲机制，避免指令误打或丢失。大厂如阿里 Tair 或字节自研 KvProxy，都会在切主期间挂起写操作直到新主健康，并确保指令重试或兜底入库，做到真正的“高可用不中断 + 指令不中途消失”。

## 🧠 总结一句话（答面试官）

> 大厂在 Redis 故障期间不会单靠 Redis 自身来保障请求安全，核心策略是：用具备主从感知能力的客户端或代理层屏蔽主从切换窗口，同时在关键路径中使用 Kafka/MQ 做落地兜底，避免请求因网络闪断或切主延迟而丢失。Redis 是快，但不能独立承担一致性职责，一定要组合方案保障完整性。



## wait策略

## ✅ 正确做法有两种（必须保证“写入 = 多副本”）

### ✅ 方式一：使用 `WAIT` 命令阻塞主节点直到至少一个从节点也确认

```
redis.set("user:balance", newBalance);
redis.wait(1, 100); // 至少1个副本在100ms内确认复制成功
```

- 如果 `WAIT` 成功 → 安心返回客户端
- 如果失败 → 返回“系统繁忙”，不扣款





# 哨兵的选举流程

## ✅ 面试回答建议：

> Redis Sentinel 在主节点宕机后，确实会进行“两轮选举”。第一轮是在 Sentinel 之间进行 Leader 选举，避免多哨兵同时发起转移造成主节点冲突；第二轮是由当选的 Sentinel Leader 发起，从多个从节点中选出一个最合适的副本作为新的主节点，并通知所有节点完成角色切换。这样的设计虽然看似重复，实则是分层治理、避免脑裂的关键。

### 🟡 第 1 层：“选 Sentinel Leader” → 是为了**避免多人指挥，场面失控**

当主节点挂掉时，多个 Sentinel 可能几乎同时探测到主节点宕机：

```
Sentinel-1：我看主挂了，我要发起故障转移！
Sentinel-2：我也看主挂了，我也要发起故障转移！
Sentinel-3：我也是，我也要抢着干活！
```

→ 💥 你就会出现：

- 多个哨兵同时在 promote 不同的从节点为新主
- 客户端连接一会儿是从 A promoted 的主节点，一会儿是 B promoted 的

**⛔ 彻底乱套，脑裂，数据全毁**

### ✅ 所以必须先选出一个“主哨兵”：

只允许它来决定谁当主！

这一步叫：

```
选举 Sentinel Leader（选出的 Sentinel 才能发起 failover）
```

> 类似于“班级代表来发起民主投票”，不是所有人都能当主持人。

------

### 🟡 第 2 层：“选 Redis 新主节点” → 是为了**让系统继续可用**

上面那个被选出来的 Sentinel Leader：

- 会根据一定规则：
  - 哪个从节点延迟最小
  - 哪个复制进度最接近主节点
  - 哪个负载低、连接快
- 从多个从节点中**挑一个最合适的当新主**

然后：

- 通知所有 Redis 节点：

  ```
  你现在跟 A 同步，B 是主了
  ```

- 更新客户端连接地址（或更新注册中心）





# redis集群和redis的哨兵sentinal是两种高可用的方案，是不一样的

## ✅ 理解本质：Sentinel vs Cluster 是两种“高可用模型”

| 特性         | Redis Sentinel（哨兵）               | Redis Cluster（集群）            |
| ------------ | ------------------------------------ | -------------------------------- |
| 主从结构     | ✅ 一主多从（典型 Master-Slave）      | ✅ 一主多从 + 分片（Slot）        |
| 故障切换机制 | ✅ Sentinel 自动故障转移主从          | ✅ 节点间自带 gossip + failover   |
| 节点通信方式 | 由外部 Sentinel 节点监控             | 集群节点内部彼此监控、选主       |
| 数据分布     | ❌ 所有主节点都存相同数据（复制）     | ✅ 数据按槽位分布在不同主节点     |
| 客户端支持   | 客户端只连主节点（变了要更新）       | 客户端必须支持 Cluster 协议      |
| 跨 slot 事务 | ✅ 有可能支持（单节点）               | ❌ 不支持跨 slot 的多 key 操作    |
| 推荐使用场景 | 中小型业务，数据量集中、单机能装得下 | 大数据量、多分片、自动分布式扩展 |

## 🧠 为什么不能把两者混起来用？

### 🚫 你不能对一个 Redis Cluster 节点再配置 Sentinel，原因如下：

1. **Redis Cluster 节点自己就带有“主从+选主+故障转移”的功能**，不需要 Sentinel。
2. Sentinel 是为“单个主节点 + 多个从节点”的结构设计的，它**看不懂 Redis Cluster 中的 Slot 映射与 Gossip 协议**。
3. Redis Cluster 本身就是一个多主架构，每个主都有自己的从，哨兵没法对多个主同时负责。

## ✅ 面试标准答法：

> ### Redis Sentinel 和 Redis Cluster 是两种完全不同的高可用机制，不能混用。Sentinel 是为单主多从的架构提供故障转移和主从切换的方案，而 Redis Cluster 是分布式架构自带主从选举与 Slot 机制的集群系统。Redis Cluster 节点之间用 Gossip 协议互相通信并实现自动主备切换，使用时必须用支持 Cluster 协议的客户端连接。因此 Redis Cluster 不再依赖 Sentinel，也不能用 Sentinel 去监控 Cluster 节点。

------

## ✅ 如果你确实需要同时拥有：

- 主从复制
- 故障自动切换
- 数据分片扩展能力

那就推荐直接用：

```
✅ Redis Cluster（自带一主一从，自动切主，分片支持）
```

哨兵是为「单点扩容」做的方案，不适合做分布式架构下的容错方案。

## ✅ 一句话总结（可怼面试官）：

> Redis Cluster 和 Sentinel 是两种互斥的高可用方案，Cluster 自带主从切换和数据分片，不需要 Sentinel；而 Sentinel 只适用于单个主节点的高可用监控，无法感知 Slot 和集群结构。二者不能也不应该混用，实际项目中会根据业务规模选其一，不会叠加使用。





















